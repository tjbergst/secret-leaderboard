{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# art contest leaderboard scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import altair as alt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ArtContestScraper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtContestScraper:\n",
    "    def __init__(self):\n",
    "        # attributes\n",
    "        self.submissions_url = lambda page: f'https://nouveaulabelcontest.com/submissions/page/{page}/'\n",
    "        self.data_dict_list = []\n",
    "        \n",
    "    \n",
    "    def randomly_sleep(self):\n",
    "        time.sleep(np.random.randint(0, 10))\n",
    "    \n",
    "    def create_entry_list(self, soup):\n",
    "        entry_list = list(set([\n",
    "            item for sublist in\n",
    "            [\n",
    "                item.find_all_previous(\n",
    "                    'a', \n",
    "                    href=re.compile(r'https://nouveaulabelcontest.com/[a-z-0-9]+/#(comments|respond)')\n",
    "                )\n",
    "                for item in soup.find_all('a', attrs={'class':'more-link style2-button'})\n",
    "            ]\n",
    "            for item in sublist\n",
    "        ]))\n",
    "        \n",
    "        entry_list.sort(key=lambda x: str(x)) \n",
    "        #print(f'entry list entry count: {len(entry_list)}')\n",
    "        \n",
    "        return entry_list\n",
    "    \n",
    "    def create_data_dict(self, soup):\n",
    "        # get entry list\n",
    "        entry_list = self.create_entry_list(soup)\n",
    "        \n",
    "        # build data dict\n",
    "        data_dict = {\n",
    "            # key\n",
    "            re.findall(\n",
    "                r'https://nouveaulabelcontest.com/([a-z-0-9]+)/',\n",
    "                entry.attrs['href']\n",
    "            )[0]: {\n",
    "                \n",
    "                # metadata subdict        \n",
    "                'link': re.findall(\n",
    "                    r'https://nouveaulabelcontest.com/[a-z-0-9]+/',\n",
    "                    entry.attrs['href']\n",
    "                )[0],\n",
    "                \n",
    "                'comments': re.findall(\n",
    "                    r'(\\d+)\\s+comments', \n",
    "                    entry.get_text()\n",
    "                )[0],\n",
    "                \n",
    "                'artist': '',\n",
    "                'title': ''\n",
    "            }\n",
    "            for entry in entry_list\n",
    "        }\n",
    "        \n",
    "        #print(f'data dict entry count: {len(data_dict.keys())}')\n",
    "        assert len(entry_list) == len(data_dict.keys()), 'entry count mismatch'\n",
    "        \n",
    "        return data_dict    \n",
    "    \n",
    "    def get_page_data(self, url):\n",
    "        # get page\n",
    "        r = requests.get(url)\n",
    "        print(f'\\tstatus: {r.status_code}')\n",
    "        \n",
    "        # soupify\n",
    "        soup = BeautifulSoup(r.content, 'lxml')    \n",
    "        \n",
    "        # build data dict\n",
    "        return self.create_data_dict(soup)\n",
    "    \n",
    "    \n",
    "    def get_entry_details(self, data_dict, key, link):\n",
    "        r = requests.get(link)\n",
    "        #print(f'status: {r.status_code}')\n",
    "    \n",
    "        soup = BeautifulSoup(r.content, 'lxml')\n",
    "        \n",
    "        # get entry metadata\n",
    "        entry_meta = soup.find_all('h4')\n",
    "        \n",
    "        # store in data dict\n",
    "        try:\n",
    "            data_dict[key]['artist'] = re.findall(r'Artist: ([A-Za-z ]+)', entry_meta[0].get_text())[0]\n",
    "        except IndexError:\n",
    "            data_dict[key]['artist'] = 'not found'\n",
    "            \n",
    "        try:\n",
    "            data_dict[key]['title'] = re.findall(r'Title: ([A-Za-z ]+)', entry_meta[1].get_text())[0]\n",
    "        except IndexError:\n",
    "            data_dict[key]['title'] = 'not found'\n",
    "                \n",
    "        return data_dict\n",
    "    \n",
    "    def get_all_entry_details(self, data_dict):\n",
    "        for key, subdict in data_dict.items():\n",
    "            self.randomly_sleep()\n",
    "            #print(f'getting details for {key}')\n",
    "            \n",
    "            data_dict = self.get_entry_details(data_dict, key, subdict['link'])\n",
    "        \n",
    "        print(f'\\tgot entry details for {len(data_dict.keys())} items')\n",
    "        return data_dict\n",
    "    \n",
    "    def page_has_data(self, url):\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content, 'lxml')\n",
    "        \n",
    "        if len(soup.find_all('a', attrs={'class':'more-link style2-button'})) > 0:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def process_data_dict_list(self):\n",
    "        # convert to records\n",
    "        data_records = [\n",
    "            {\n",
    "                'key': key,\n",
    "                'link': subdict['link'],\n",
    "                'title': subdict['title'],\n",
    "                'artist': subdict['artist'],\n",
    "                'comments': subdict['comments']\n",
    "            }\n",
    "            for data in self.data_dict_list\n",
    "            for key, subdict in data.items()    \n",
    "        ]\n",
    "        \n",
    "        # load dataframe\n",
    "        self.alt_df = (\n",
    "            pd\n",
    "            .DataFrame(data_records)\n",
    "            .assign(\n",
    "                # set dtype\n",
    "                comments = lambda x: x.comments.astype('int'),\n",
    "                \n",
    "                # mark target\n",
    "                dummy = lambda x: [\n",
    "                    'deep-green' \n",
    "                        if artist == 'Reuf Kapetanovic'\n",
    "                        else 'other'\n",
    "                    for artist in x.artist\n",
    "                ],\n",
    "                \n",
    "                # fill titles\n",
    "                title = lambda x: [\n",
    "                    key\n",
    "                        if title == 'not found'\n",
    "                        else title\n",
    "                    for key, title in zip(x.key, x.title)\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        print(f'created dataframe, {self.alt_df.shape[0]} entries')\n",
    "        \n",
    "    \n",
    "    def generate_leaderboard_chart(self):\n",
    "        # explicit sort list\n",
    "        sort_list = list(\n",
    "            self\n",
    "            .alt_df\n",
    "            .query('comments > 0')\n",
    "            .sort_values('comments', ascending=False)\n",
    "            .key\n",
    "            .values\n",
    "        )\n",
    "        \n",
    "        # chart\n",
    "        self.rank_chart = alt.Chart(\n",
    "            self.alt_df.query('comments > 0')\n",
    "        ).mark_bar(\n",
    "        ).encode(\n",
    "            alt.Y(\n",
    "                'key:N',\n",
    "                sort=sort_list\n",
    "            ),\n",
    "            alt.X(\n",
    "                'comments:Q',\n",
    "                axis=alt.Axis(orient='top')\n",
    "            ),\n",
    "            color='dummy:N',\n",
    "            href='link',\n",
    "            tooltip=[\n",
    "                alt.Tooltip('artist:N'),\n",
    "                alt.Tooltip('title:N'),\n",
    "                alt.Tooltip('comments:Q')\n",
    "            ]\n",
    "        ).properties(\n",
    "            title='comment count by submission'\n",
    "        ).configure(\n",
    "            #background='#abb2bf'\n",
    "        )\n",
    "        \n",
    "        display(self.rank_chart)\n",
    "        try:\n",
    "            self.rank_chart.save('rank-chart.png')\n",
    "        except Exception as e:\n",
    "            print(f'exception encountered: {e}')\n",
    "    \n",
    "    def main(self):\n",
    "        i = 1\n",
    "        start_time = time.time()\n",
    "        \n",
    "        while True:\n",
    "            if self.page_has_data(self.submissions_url(i)):\n",
    "                self.randomly_sleep()\n",
    "                print(f'getting page {i}')\n",
    "        \n",
    "                # get all details\n",
    "                data_dict = self.get_all_entry_details(\n",
    "                    self.get_page_data(\n",
    "                        self.submissions_url(i)\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                self.data_dict_list.append(data_dict)                \n",
    "                i += 1\n",
    "            \n",
    "            else:\n",
    "                print(f'scrape complete, elapsed time: {(time.time() - start_time)/60:0.1f} minutes')\n",
    "                break\n",
    "        \n",
    "        self.process_data_dict_list()\n",
    "        self.generate_leaderboard_chart()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS = ArtContestScraper()\n",
    "ACS.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS.alt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_df =  ACS.alt_df\n",
    "\n",
    "%store alt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
